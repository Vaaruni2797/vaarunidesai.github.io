---
layout: home
---
<img src="imgs/profile.png" alt="avatar" 
     style="width: 200px; height: 200px; border-radius: 80%; align: center"/>
     
Welcome! I am Vaaruni Desai. 

I am an AI researcher obsessed with how transformers think.
I specialize in building probing tools to align AI to human goals.

Past work include: 
<div style="display: flex; gap: 16px;">

  <div style="flex: 1; border: 1px solid #ddd; border-radius: 8px; padding: 16px;">
    <img src="imgs/fff.png" alt="FinetuningForFlashcards" style="width: 100%; border-radius: 6px;"/>
    <h3><a href="https://github.com/Vaaruni2797/FinetuningForFlashcards">FinetuningForFlashcards</a></h3>
    <p>AI-powered flashcard generator using fine-tuned transformers.</p>
  </div>

  <div style="flex: 1; border: 1px solid #ddd; border-radius: 8px; padding: 16px;">
    <img src="imgs/pcot.png" alt="pickucot" style="width: 100%; border-radius: 6px;"/>
    <h3><a href="https://github.com/Vaaruni2797/pickucot">pickucot</a></h3>
    <p>Framework for probing causal hint use and explanation faithfulness.</p>
  </div>

  <div style="flex: 1; border: 1px solid #ddd; border-radius: 8px; padding: 16px;">
    <img src="imgs/mlp.png" alt="Attention-MLPs-in-Transformer-XOR" style="width: 100%; border-radius: 6px;"/>
    <h3><a href="https://github.com/Vaaruni2797/Attention-MLPs-in-Transformer-XOR">Attention-MLPs-in-Transformer-XOR</a></h3>
    <p>Experiments analyzing grokking, attention entropy, and representation phase transitions.</p>
  </div>

</div>
