---
layout: page
title: About
permalink: /about/
---

I’m an AI researcher specializing in interpretability, alignment, and transformer training dynamics.

I build and analyze probing pipelines that quantify how syntactic structure emerges across model layers and training checkpoints. My work includes attention entropy studies, PCA-based representation dynamics, and longitudinal experiments that track how reasoning circuits evolve.

During my time as an AI Alignment Research Fellow with the AI Safety Global Society, I ran large-scale transformer experiments—often over 100,000+ epochs—to study reasoning behavior in structured tasks like XOR and parity. I also designed **pickucot**, a framework for examining causal hint use and explanation faithfulness.

Before research, I engineered secure and high‑performance REST APIs at Refinitiv (LSEG) and Thomson Reuters.

I hold a Master’s in Data Science & Engineering from UC San Diego.
